{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP3 - Population d'un graphe RDF à partir de texte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Configuration et Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-12-14 22:02:15.051530: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-12-14 22:02:15.082266: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-12-14 22:02:15.703664: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "from rdflib import Graph, URIRef, Namespace\n",
    "\n",
    "# Configuration DBpedia Spotlight\n",
    "SPOTLIGHT_ENDPOINT = \"https://api.dbpedia-spotlight.org/en/annotate\"\n",
    "SPOTLIGHT_CONFIDENCE = 0.5\n",
    "SPOTLIGHT_SUPPORT = 10\n",
    "API_DELAY = 0.2  # délai entre appels API pour éviter le rate limiting\n",
    "\n",
    "# Configuration REBEL\n",
    "REBEL_MAX_LENGTH = 512\n",
    "REBEL_NUM_BEAMS = 3\n",
    "\n",
    "# Namespace pour les entités/relations locales\n",
    "EX = Namespace(\"http://example.org/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Fonctions utilitaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_triplets(text: str) -> list[dict]:\n",
    "    \"\"\"Parse la sortie REBEL pour extraire les triplets (head, type, tail).\"\"\"\n",
    "    triplets = []\n",
    "    relation, subject, object_ = '', '', ''\n",
    "    text = text.strip()\n",
    "    current = 'x'\n",
    "    \n",
    "    for token in text.replace(\"<s>\", \"\").replace(\"<pad>\", \"\").replace(\"</s>\", \"\").split():\n",
    "        if token == \"<triplet>\":\n",
    "            current = 't'\n",
    "            if relation != '':\n",
    "                triplets.append({'head': subject.strip(), 'type': relation.strip(), 'tail': object_.strip()})\n",
    "                relation = ''\n",
    "            subject = ''\n",
    "        elif token == \"<subj>\":\n",
    "            current = 's'\n",
    "            if relation != '':\n",
    "                triplets.append({'head': subject.strip(), 'type': relation.strip(), 'tail': object_.strip()})\n",
    "            object_ = ''\n",
    "        elif token == \"<obj>\":\n",
    "            current = 'o'\n",
    "            relation = ''\n",
    "        else:\n",
    "            if current == 't':\n",
    "                subject += ' ' + token\n",
    "            elif current == 's':\n",
    "                object_ += ' ' + token\n",
    "            elif current == 'o':\n",
    "                relation += ' ' + token\n",
    "                \n",
    "    if subject != '' and relation != '' and object_ != '':\n",
    "        triplets.append({'head': subject.strip(), 'type': relation.strip(), 'tail': object_.strip()})\n",
    "    \n",
    "    return triplets\n",
    "\n",
    "\n",
    "def get_dbpedia_uri(entity: str, confidence: float = SPOTLIGHT_CONFIDENCE, support: int = SPOTLIGHT_SUPPORT) -> str | None:\n",
    "    \"\"\"Interroge DBpedia Spotlight pour obtenir l'URI d'une entité.\"\"\"\n",
    "    params = {\"text\": entity, \"confidence\": confidence, \"support\": support}\n",
    "    headers = {\"Accept\": \"application/json\"}\n",
    "    \n",
    "    try:\n",
    "        time.sleep(API_DELAY)\n",
    "        response = requests.get(SPOTLIGHT_ENDPOINT, params=params, headers=headers, timeout=15)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            if 'Resources' in data:\n",
    "                best = max(data['Resources'], key=lambda x: float(x.get('@similarityScore', '0')))\n",
    "                return best.get('@URI')\n",
    "    except Exception:\n",
    "        pass\n",
    "    \n",
    "    return None\n",
    "\n",
    "\n",
    "def build_rdf_graph(triplets: list[dict], verbose: bool = True) -> Graph:\n",
    "    \"\"\"Construit un graphe RDF à partir des triplets extraits.\"\"\"\n",
    "    g = Graph()\n",
    "    \n",
    "    # Collecter toutes les entités uniques\n",
    "    entities = {t['head'] for t in triplets} | {t['tail'] for t in triplets}\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Recherche d'URIs pour {len(entities)} entités...\")\n",
    "    \n",
    "    # Résoudre les URIs (DBpedia ou fallback local)\n",
    "    uri_cache = {}\n",
    "    for entity in entities:\n",
    "        uri = get_dbpedia_uri(entity)\n",
    "        if uri:\n",
    "            uri_cache[entity] = URIRef(uri)\n",
    "            if verbose:\n",
    "                print(f\"  {entity} -> {uri}\")\n",
    "        else:\n",
    "            local_uri = EX[entity.replace(\" \", \"_\")]\n",
    "            uri_cache[entity] = local_uri\n",
    "            if verbose:\n",
    "                print(f\"  {entity} -> {local_uri} (local)\")\n",
    "    \n",
    "    # Ajouter les triplets au graphe\n",
    "    for t in triplets:\n",
    "        subject = uri_cache[t['head']]\n",
    "        obj = uri_cache[t['tail']]\n",
    "        predicate = EX[t['type'].replace(\" \", \"_\").replace(\"-\", \"_\")]\n",
    "        g.add((subject, predicate, obj))\n",
    "    \n",
    "    return g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Chargement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Texte découpé en 9 blocs (paragraphes).\n",
      "Premier bloc : Geoffrey Everest Hinton (born 6 December 1947) is an English Canadian cognitive psychologist and com...\n"
     ]
    }
   ],
   "source": [
    "with open(\"texte_a_analyser.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    text_source = f.read()\n",
    "\n",
    "blocs = [b.strip() for b in text_source.split('\\n') if b.strip()]\n",
    "\n",
    "print(f\"Texte découpé en {len(blocs)} blocs (paragraphes).\")\n",
    "print(f\"Premier bloc : {blocs[0][:100]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Extraction des triplets avec REBEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Chargement du modèle REBEL (téléchargement ~1.6 Go au premier lancement)\n",
    "triplet_extractor = pipeline(\n",
    "    'text2text-generation',\n",
    "    model='Babelscape/rebel-large',\n",
    "    tokenizer='Babelscape/rebel-large'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bloc 1/9 : 5 triplets\n",
      "Bloc 2/9 : 2 triplets\n",
      "Bloc 3/9 : 1 triplets\n",
      "Bloc 4/9 : 2 triplets\n",
      "Bloc 5/9 : 1 triplets\n",
      "Bloc 6/9 : 1 triplets\n",
      "Bloc 7/9 : 2 triplets\n",
      "Bloc 8/9 : 1 triplets\n",
      "Bloc 9/9 : 2 triplets\n",
      "\n",
      "Total : 17 triplets extraits\n"
     ]
    }
   ],
   "source": [
    "all_triplets = []\n",
    "\n",
    "for i, bloc in enumerate(blocs):\n",
    "    # Génération avec REBEL\n",
    "    out = triplet_extractor(\n",
    "        bloc,\n",
    "        max_length=REBEL_MAX_LENGTH,\n",
    "        num_beams=REBEL_NUM_BEAMS,\n",
    "        return_tensors=True,\n",
    "        return_text=False\n",
    "    )[0][\"generated_token_ids\"]\n",
    "\n",
    "    # Décodage en gardant les tokens spéciaux\n",
    "    raw_output = triplet_extractor.tokenizer.batch_decode([out], skip_special_tokens=False)[0]\n",
    "    \n",
    "    # Extraction des triplets\n",
    "    triplets = extract_triplets(raw_output)\n",
    "    all_triplets.extend(triplets)\n",
    "    print(f\"Bloc {i+1}/{len(blocs)} : {len(triplets)} triplets\")\n",
    "\n",
    "print(f\"\\nTotal : {len(all_triplets)} triplets extraits\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>head</th>\n",
       "      <th>type</th>\n",
       "      <th>tail</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Everest Hinton</td>\n",
       "      <td>date of birth</td>\n",
       "      <td>6 December 1947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Everest Hinton</td>\n",
       "      <td>occupation</td>\n",
       "      <td>computer scientist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Everest Hinton</td>\n",
       "      <td>field of work</td>\n",
       "      <td>artificial neural network</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Everest Hinton</td>\n",
       "      <td>employer</td>\n",
       "      <td>University of Toronto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>artificial neural network</td>\n",
       "      <td>part of</td>\n",
       "      <td>cognitive psychologist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AlexNet</td>\n",
       "      <td>discoverer or inventor</td>\n",
       "      <td>Alex Krizhevsky</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Alex Krizhevsky</td>\n",
       "      <td>notable work</td>\n",
       "      <td>AlexNet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Christopher Longuet-Higgins</td>\n",
       "      <td>employer</td>\n",
       "      <td>University of Edinburgh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Google</td>\n",
       "      <td>subsidiary</td>\n",
       "      <td>DNNresearch Inc.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>DNNresearch Inc.</td>\n",
       "      <td>parent organization</td>\n",
       "      <td>Google</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>neural network</td>\n",
       "      <td>use</td>\n",
       "      <td>machine learning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>David E. Rumelhart</td>\n",
       "      <td>educated at</td>\n",
       "      <td>Carnegie Mellon University</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Boltzmann machine</td>\n",
       "      <td>discoverer or inventor</td>\n",
       "      <td>David Ackley</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Boltzmann machine</td>\n",
       "      <td>discoverer or inventor</td>\n",
       "      <td>Terry Sejnowski</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>open-access</td>\n",
       "      <td>subclass of</td>\n",
       "      <td>research papers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Richard Zemel</td>\n",
       "      <td>student</td>\n",
       "      <td>Brendan Frey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Brendan Frey</td>\n",
       "      <td>student of</td>\n",
       "      <td>Richard Zemel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           head                    type  \\\n",
       "0                Everest Hinton           date of birth   \n",
       "1                Everest Hinton              occupation   \n",
       "2                Everest Hinton           field of work   \n",
       "3                Everest Hinton                employer   \n",
       "4     artificial neural network                 part of   \n",
       "5                       AlexNet  discoverer or inventor   \n",
       "6               Alex Krizhevsky            notable work   \n",
       "7   Christopher Longuet-Higgins                employer   \n",
       "8                        Google              subsidiary   \n",
       "9              DNNresearch Inc.     parent organization   \n",
       "10               neural network                     use   \n",
       "11           David E. Rumelhart             educated at   \n",
       "12            Boltzmann machine  discoverer or inventor   \n",
       "13            Boltzmann machine  discoverer or inventor   \n",
       "14                  open-access             subclass of   \n",
       "15                Richard Zemel                 student   \n",
       "16                 Brendan Frey              student of   \n",
       "\n",
       "                          tail  \n",
       "0              6 December 1947  \n",
       "1           computer scientist  \n",
       "2    artificial neural network  \n",
       "3        University of Toronto  \n",
       "4       cognitive psychologist  \n",
       "5              Alex Krizhevsky  \n",
       "6                      AlexNet  \n",
       "7      University of Edinburgh  \n",
       "8             DNNresearch Inc.  \n",
       "9                       Google  \n",
       "10            machine learning  \n",
       "11  Carnegie Mellon University  \n",
       "12                David Ackley  \n",
       "13             Terry Sejnowski  \n",
       "14             research papers  \n",
       "15                Brendan Frey  \n",
       "16               Richard Zemel  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aperçu des triplets extraits\n",
    "pd.DataFrame(all_triplets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analyse des paramètres DBpedia Spotlight (optionnel)\n",
    "\n",
    "Cette section teste différentes valeurs de `confidence` et `support` pour évaluer leur impact sur le linking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_spotlight_params(entities: list[str], param_grid: list[tuple]) -> pd.DataFrame:\n",
    "    \"\"\"Évalue l'impact des paramètres Spotlight sur le taux de linking.\"\"\"\n",
    "    rows = []\n",
    "    \n",
    "    for conf, supp in param_grid:\n",
    "        linked = 0\n",
    "        for entity in entities:\n",
    "            uri = get_dbpedia_uri(entity, conf, supp)\n",
    "            if uri and \"dbpedia.org/resource/\" in uri:\n",
    "                linked += 1\n",
    "        \n",
    "        rows.append({\n",
    "            \"confidence\": conf,\n",
    "            \"support\": supp,\n",
    "            \"entities_tested\": len(entities),\n",
    "            \"linked_dbpedia\": linked,\n",
    "            \"linked_pct\": linked / len(entities)\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(rows).sort_values(\"linked_dbpedia\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>confidence</th>\n",
       "      <th>support</th>\n",
       "      <th>entities_tested</th>\n",
       "      <th>linked_dbpedia</th>\n",
       "      <th>linked_pct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.20</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.35</td>\n",
       "      <td>20</td>\n",
       "      <td>23</td>\n",
       "      <td>16</td>\n",
       "      <td>0.695652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.50</td>\n",
       "      <td>10</td>\n",
       "      <td>23</td>\n",
       "      <td>16</td>\n",
       "      <td>0.695652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.70</td>\n",
       "      <td>50</td>\n",
       "      <td>23</td>\n",
       "      <td>13</td>\n",
       "      <td>0.565217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   confidence  support  entities_tested  linked_dbpedia  linked_pct\n",
       "0        0.20        0               23              23    1.000000\n",
       "1        0.35       20               23              16    0.695652\n",
       "2        0.50       10               23              16    0.695652\n",
       "3        0.70       50               23              13    0.565217"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Entités uniques à tester\n",
    "entities_to_test = sorted({t[\"head\"] for t in all_triplets} | {t[\"tail\"] for t in all_triplets})\n",
    "\n",
    "# Grille de paramètres\n",
    "param_grid = [\n",
    "    (0.20, 0),\n",
    "    (0.35, 20),\n",
    "    (0.50, 10),\n",
    "    (0.70, 50),\n",
    "]\n",
    "\n",
    "df_params = evaluate_spotlight_params(entities_to_test, param_grid)\n",
    "df_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\caption{Impact des paramètres confidence et support sur la couverture DBpedia Spotlight.}\n",
      "\\label{tab:spotlight_params}\n",
      "\\begin{tabular}{rrrrr}\n",
      "\\toprule\n",
      "confidence & support & entities_tested & linked_dbpedia & linked_pct \\\\\n",
      "\\midrule\n",
      "0.20 & 0 & 23 & 23 & 1.00 \\\\\n",
      "0.35 & 20 & 23 & 16 & 0.70 \\\\\n",
      "0.50 & 10 & 23 & 16 & 0.70 \\\\\n",
      "0.70 & 50 & 23 & 13 & 0.57 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Export LaTeX pour le rapport\n",
    "print(df_params.to_latex(\n",
    "    index=False,\n",
    "    float_format=\"%.2f\",\n",
    "    caption=\"Impact des paramètres confidence et support sur la couverture DBpedia Spotlight.\",\n",
    "    label=\"tab:spotlight_params\"\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Construction du graphe RDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recherche d'URIs pour 23 entités...\n",
      "  Terry Sejnowski -> http://dbpedia.org/resource/Terry_Sejnowski\n",
      "  Richard Zemel -> http://example.org/Richard_Zemel (local)\n",
      "  Alex Krizhevsky -> http://example.org/Alex_Krizhevsky (local)\n",
      "  computer scientist -> http://dbpedia.org/resource/Computer_scientist\n",
      "  machine learning -> http://dbpedia.org/resource/Machine_learning\n",
      "  research papers -> http://example.org/research_papers (local)\n",
      "  University of Toronto -> http://dbpedia.org/resource/Toronto\n",
      "  open-access -> http://dbpedia.org/resource/Open_access\n",
      "  cognitive psychologist -> http://dbpedia.org/resource/Cognitive_psychology\n",
      "  Christopher Longuet-Higgins -> http://dbpedia.org/resource/Christopher_Longuet-Higgins\n",
      "  neural network -> http://dbpedia.org/resource/Neural_network\n",
      "  Google -> http://dbpedia.org/resource/Google\n",
      "  Everest Hinton -> http://dbpedia.org/resource/Mount_Everest\n",
      "  David E. Rumelhart -> http://dbpedia.org/resource/David_Rumelhart\n",
      "  DNNresearch Inc. -> http://example.org/DNNresearch_Inc. (local)\n",
      "  Brendan Frey -> http://example.org/Brendan_Frey (local)\n",
      "  AlexNet -> http://example.org/AlexNet (local)\n",
      "  Carnegie Mellon University -> http://dbpedia.org/resource/Carnegie_Mellon_University\n",
      "  6 December 1947 -> http://example.org/6_December_1947 (local)\n",
      "  David Ackley -> http://example.org/David_Ackley (local)\n",
      "  artificial neural network -> http://dbpedia.org/resource/Neural_network\n",
      "  Boltzmann machine -> http://dbpedia.org/resource/Boltzmann_machine\n",
      "  University of Edinburgh -> http://dbpedia.org/resource/Edinburgh\n"
     ]
    }
   ],
   "source": [
    "graph = build_rdf_graph(all_triplets, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graphe exporté dans graph.ttl\n"
     ]
    }
   ],
   "source": [
    "# Export en Turtle\n",
    "graph.serialize(\"graph.ttl\", format=\"turtle\")\n",
    "print(\"Graphe exporté dans graph.ttl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@prefix ns1: <http://example.org/> .\n",
      "\n",
      "<http://dbpedia.org/resource/Boltzmann_machine> ns1:discoverer_or_inventor <http://dbpedia.org/resource/Terry_Sejnowski>,\n",
      "        ns1:David_Ackley .\n",
      "\n",
      "<http://dbpedia.org/resource/Christopher_Longuet-Higgins> ns1:employer <http://dbpedia.org/resource/Edinburgh> .\n",
      "\n",
      "<http://dbpedia.org/resource/David_Rumelhart> ns1:educated_at <http://dbpedia.org/resource/Carnegie_Mellon_University> .\n",
      "\n",
      "<http://dbpedia.org/resource/Mount_Everest> ns1:date_of_birth ns1:6_December_1947 ;\n",
      "    ns1:employer <http://dbpedia.org/resource/Toronto> ;\n",
      "    ns1:field_of_work <http://dbpedia.org/resource/Neural_network> ;\n",
      "    ns1:occupation <http://dbpedia.org/resource/Computer_scientist> .\n",
      "\n",
      "<http://dbpedia.org/resource/Open_access> ns1:subclass_of ns1:research_papers .\n",
      "\n",
      "<http://dbpedia.org/resource/Google> ns1:subsidiary <http://example.org/DNNresearch_Inc.> .\n",
      "\n",
      "<http://dbpedia.org/resource/Neural_network> ns1:part_of <http://dbpedia.org/resource/Cognitive_psychology> ;\n",
      "    ns1:use <http://dbpedia.org/resource/Machine_learning> .\n",
      "\n",
      "ns1:AlexNet ns1:discoverer_or_inventor ns1:Alex_Krizhevsky .\n",
      "\n",
      "ns1:Alex_Krizhevsky ns1:notable_work ns1:AlexNet .\n",
      "\n",
      "ns1:Brendan_Frey ns1:student_of ns1:Richard_Zemel .\n",
      "\n",
      "<http://example.org/DNNresearch_Inc.> ns1:parent_organization <http://dbpedia.org/resource/Google> .\n",
      "\n",
      "ns1:Richard_Zemel ns1:student ns1:Brendan_Frey .\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Affichage du graphe\n",
    "print(graph.serialize(format='turtle'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\caption{Statistiques du graphe RDF généré.}\n",
      "\\label{tab:graph_stats}\n",
      "\\begin{tabular}{rrrrr}\n",
      "\\toprule\n",
      "triples & nodes & predicates & dbpedia_nodes & local_nodes \\\\\n",
      "\\midrule\n",
      "17 & 22 & 14 & 14 & 8 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node</th>\n",
       "      <th>degree</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://dbpedia.org/resource/Mount_Everest</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://dbpedia.org/resource/Neural_network</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://dbpedia.org/resource/Boltzmann_machine</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://example.org/Alex_Krizhevsky</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://example.org/AlexNet</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>http://example.org/Richard_Zemel</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>http://example.org/Brendan_Frey</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>http://example.org/DNNresearch_Inc.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            node  degree\n",
       "0      http://dbpedia.org/resource/Mount_Everest       4\n",
       "1     http://dbpedia.org/resource/Neural_network       3\n",
       "2  http://dbpedia.org/resource/Boltzmann_machine       2\n",
       "3             http://example.org/Alex_Krizhevsky       2\n",
       "4                     http://example.org/AlexNet       2\n",
       "5               http://example.org/Richard_Zemel       2\n",
       "6                http://example.org/Brendan_Frey       2\n",
       "7            http://example.org/DNNresearch_Inc.       2"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "# --- Stats rapides ---\n",
    "subjects = {s for s,p,o in graph}\n",
    "objects  = {o for s,p,o in graph}\n",
    "preds    = {p for s,p,o in graph}\n",
    "nodes    = subjects | objects\n",
    "\n",
    "is_dbpedia = lambda u: str(u).startswith(\"http://dbpedia.org/resource/\")\n",
    "is_local   = lambda u: str(u).startswith(\"http://example.org/\")\n",
    "\n",
    "stats = {\n",
    "    \"triples\": len(graph),\n",
    "    \"nodes\": len(nodes),\n",
    "    \"predicates\": len(preds),\n",
    "    \"dbpedia_nodes\": sum(is_dbpedia(n) for n in nodes),\n",
    "    \"local_nodes\": sum(is_local(n) for n in nodes),\n",
    "}\n",
    "df_stats = pd.DataFrame([stats])\n",
    "df_stats\n",
    "\n",
    "print(df_stats.to_latex(\n",
    "    index=False,\n",
    "    caption=\"Statistiques du graphe RDF généré.\",\n",
    "    label=\"tab:graph_stats\"\n",
    "))\n",
    "\n",
    "# --- Centralité naïve (degré) pour discuter la structure ---\n",
    "deg = Counter()\n",
    "for s,p,o in graph:\n",
    "    deg[s] += 1\n",
    "    deg[o] += 1\n",
    "\n",
    "df_deg = pd.DataFrame([(str(n), d) for n,d in deg.most_common(8)], columns=[\"node\", \"degree\"])\n",
    "df_deg\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
